{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vehicle-Recognition-MobileNet-SVM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5m9flLdyM4-u"
      },
      "source": [
        "## Introduction\n",
        "This is a demonstration notebook of training a deep architecture ([MobileNet V1](https://arxiv.org/abs/1704.04861)) on an unsupervised image dataset of vehicle models from a marketing site. This dataset was analysed in depth during my previous work of [*Transfer learning approach for classification and noise reduction on noisy web data*](https://www.sciencedirect.com/science/article/pii/S0957417418301878?via%3Dihub)\". In this notebook, the architecture is trained on the entire noisy dataset with two learning strategies. In the first one, the network is thorouly trained and fine-tuned on the dataset, and in the second approach, the network is used as a feature extractor and the features are classified using a linear support vector classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2R347SWrrqS",
        "colab_type": "text"
      },
      "source": [
        "## Dataset preparation phase\n",
        "### Prepare to download the dataset (from Megaupload)\n",
        "\n",
        "The provided dataset is available at Megaupload server, hence an auxilary tool, called 'Megatools' is required to download this dataset. The following commands attempt to download and extract the latest version of this program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBExk1ndnJUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir tools -p\n",
        "!wget -c \"https://megatools.megous.com/builds/experimental/megatools-1.11.0-git-20180814-linux-x86_64.tar.gz\" -O \"tools/megatools.tar.gz\"\n",
        "!tar xfz \"tools/megatools.tar.gz\" --directory \"tools/\"\n",
        "!mv \"tools/megatools-1.11.0-git-20180814-linux-x86_64/\" \"tools/megatools\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83-Bii_ptfX1",
        "colab_type": "text"
      },
      "source": [
        "### Download the dataset\n",
        "The following commands will download and extract the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUc6BVvyD3ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir download -p\n",
        "!mkdir datasets -p\n",
        "!mkdir \"datasets/clean_dataset/\" -p\n",
        "!mkdir \"datasets/main_dataset/\" -p\n",
        "!./tools/megatools/megatools dl \"https://mega.nz/#F!RDZRyIAC!eX1au64E9TGw07BqEOeVLQ\" --path='download/'\n",
        "!tar xf \"download/clean_dataset.tar\" --directory \"datasets/clean_dataset/\"\n",
        "!tar xf \"download/main_dataset.tar\" --directory \"datasets/main_dataset/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzCrZ2gGmcJE",
        "colab_type": "text"
      },
      "source": [
        "### Delete the images that are not required\n",
        "As the entire noisy images are stored in a single archive, the unwanted files should be erased.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgZ5WaA5tXfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!for name in $(cat datasets/main_dataset/labels/test/all.txt) ; do  if [[ ${#name}>2 ]]; then  rm \"$name\" -f ; fi ; done"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNb2T1K_VZrN",
        "colab_type": "text"
      },
      "source": [
        "## Dataset preparation phase (using Google drive)\n",
        "###Copy the dataset from Google Drive path\n",
        "If you are using Colab, you can download the dataset into your google drive and use it by running the following commands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB6vwWjIWEcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import google drive library\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!mkdir download -p\n",
        "!mkdir datasets -p\n",
        "!mkdir \"datasets/clean_dataset/\" -p\n",
        "!mkdir \"datasets/main_dataset/\" -p\n",
        "!cp \"/content/gdrive/My Drive/Datasets/clean_dataset.tar\" /content/download/clean_dataset.tar\n",
        "!cp \"/content/gdrive/My Drive/Datasets/main_dataset.tar\" /content/download/main_dataset.tar\n",
        "!tar xf \"download/clean_dataset.tar\" --directory \"datasets/clean_dataset/\"\n",
        "!tar xf \"download/main_dataset.tar\" --directory \"datasets/main_dataset/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SufRpIpToJoR",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the code\n",
        "### Download and compile the latest version of *Liblinear* library\n",
        "We are using a  liblinear which is a fast implementation of a linear support vector classifier. The latest version of this tool is downloaded and compiled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQE7Eoy-9idM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir tools/liblinear -p\n",
        "!git clone \"https://github.com/cjlin1/liblinear.git\" tools/liblinear/\n",
        "!make -C tools/liblinear/python/ -s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXYxZ_AzAKV9",
        "colab_type": "text"
      },
      "source": [
        "### Copy the required files to the working directory \n",
        "To be able to work with liblinear module, only the python wrapper files and liblinear  shared object are required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU7TXyquDFwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp tools/liblinear/python/liblinear.py liblinear.py\n",
        "!cp tools/liblinear/python/liblinearutil.py liblinearutil.py\n",
        "!cp tools/liblinear/python/commonutil.py commonutil.py\n",
        "!cp tools/liblinear/liblinear.so.3 /liblinear.so.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoGLvW2TBJMz",
        "colab_type": "text"
      },
      "source": [
        "### Import the required modules and libraries\n",
        "The major libraries required by this notebook are tensorflow and liblinear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh9AmAFuFHTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import liblinearutil as libl\n",
        "\n",
        "# print tensorflow version and GPU device name (if there exists one)\n",
        "print(\"TensorFlow version is \", tf.__version__)\n",
        "print(\"GPU device name: \", tf.test.gpu_device_name())\n",
        "print(\"Available CPUs: \", multiprocessing.cpu_count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRL1ycghBmpU",
        "colab_type": "text"
      },
      "source": [
        "### Define the parameters\n",
        "\n",
        "The first version of MobileNet being compatible with Tensorflow.js is used here, and the rest of the parameters and hyper-parameters are defined here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzaVEJOhFoT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network definitions\n",
        "input_size = 224 \n",
        "\n",
        "# Dataset definitions\n",
        "train_path = 'datasets/main_dataset/images/'\n",
        "val_path = 'datasets/clean_dataset/images/'\n",
        "class_count = 9 \n",
        "rescale_factor = 1./255\n",
        "\n",
        "# Storing parameters\n",
        "model_name = \"mobilenet_vr_svm.h5\"\n",
        "\n",
        "# Training parameters\n",
        "svm_c_values = [10 ** i for i in range(-4,2)] \n",
        "train_batch_size = 64\n",
        "val_batch_size = 64\n",
        "\n",
        "# Define feature extraction and svm layer\n",
        "fe_layer = 1\n",
        "svm_layer = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBmP28ojBtOu",
        "colab_type": "text"
      },
      "source": [
        "### Create dataset generators\n",
        "The ImageDataGenerator is used for the ease of dealing with the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFrkaSU6Frma",
        "colab_type": "code",
        "outputId": "afe9a836-9b79-4a77-af43-0ab10bb958f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Create training generator\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=rescale_factor)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                train_path,  \n",
        "                target_size=(input_size, input_size),  \n",
        "                batch_size=train_batch_size,             \n",
        "                class_mode='sparse')\n",
        "\n",
        "\n",
        "# Create validation generator\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=rescale_factor)\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "                val_path,\n",
        "                target_size=(input_size, input_size),\n",
        "                batch_size=val_batch_size,\n",
        "                class_mode='sparse')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 45000 images belonging to 9 classes.\n",
            "Found 6300 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WubWv1tBzBY",
        "colab_type": "text"
      },
      "source": [
        "### Define the Network\n",
        "The MobileNet architecture is defined as the feature extractor, and the model is augmented with a fully connected layer that will be used to embed the svm parameters after the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urji3kO_F2_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the base model from the pre-trained MobileNet\n",
        "base_model = tf.keras.applications.MobileNet(input_shape=(input_size, input_size, 3),\n",
        "                                               include_top=False, \n",
        "                                               weights='imagenet')\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "# create the final model by stacking an average pooling layer together with a softmax fully connected layer \n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    # svm parameters will be embedded here\n",
        "    tf.keras.layers.Dense(9,activation='linear',use_bias=False)\n",
        "])\n",
        "\n",
        "# feature extraction layer\n",
        "act_layer = tf.keras.models.Model(inputs = model.input, outputs=model.layers[fe_layer].output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXdoU18Gd7do",
        "colab_type": "text"
      },
      "source": [
        "### Feed the images and extract the features\n",
        "The entire training and validation images are fed into the network and the features are stored for further use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSoNU-HDGfl3",
        "colab_type": "code",
        "outputId": "f2b93338-1ad1-4a79-ccb7-e2212583b811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def extract_features(layer,generator,steps = None):\n",
        "  # temporary variables\n",
        "  data = []\n",
        "  labels = []\n",
        "  \n",
        "  # determine number of batches \n",
        "  if steps is None:\n",
        "    steps = len(generator)\n",
        "   \n",
        "  # iterate through batches \n",
        "  for index in range(steps):\n",
        "    # get the next batch\n",
        "    img_batch,lb_batch = generator.next()\n",
        "    # extract features\n",
        "    features = layer.predict(img_batch) \n",
        "    # append extracted features and labels\n",
        "    data.append(features)\n",
        "    labels.append(lb_batch)\n",
        "    \n",
        "  return np.vstack(data),np.hstack(labels)\n",
        "  \n",
        "# extract the features from training images\n",
        "train_data,train_lb = extract_features(act_layer,train_generator)\n",
        "# extract the features from validation images\n",
        "val_data,val_lb = extract_features(act_layer,val_generator)\n",
        "\n",
        "\n",
        "# Show the stats of the extracted features\n",
        "print(\"Training data size: \",train_data.shape)\n",
        "print(\"Validation data size: \",val_data.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size:  (45000, 1024)\n",
            "Validation data size:  (6300, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gecDAF-8mDZP",
        "colab_type": "text"
      },
      "source": [
        "## Training phase\n",
        "### Train the support vector classifier \n",
        "The model is trained using different C parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9nTCRzXGr4H",
        "colab_type": "code",
        "outputId": "11d3e0bf-f2e4-458f-e683-32f951214bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "svm_models = []\n",
        "svm_acc = []\n",
        "for c in svm_c_values:\n",
        "  print(\"Training the model with C = %0.6f\" % c)\n",
        "  current_model = libl.train(train_lb,train_data,'-c %0.6f' % c)\n",
        "  # get training accuracy and loss\n",
        "  _pred_labels, (T_ACC, MSE, SCC), _pred_values=libl.predict(train_lb,train_data,current_model,'-q')\n",
        "  # get validation accuracy and loss\n",
        "  _pred_labels, (V_ACC, MSE, SCC), _pred_values=libl.predict(val_lb,val_data,current_model,'-q')\n",
        "  print(\"Training Accuracy: \", T_ACC , \"- Validation Accuracy: \", V_ACC ,\"\\n\")\n",
        "  \n",
        "  # add current model to the list\n",
        "  svm_models.append(current_model)\n",
        "  svm_acc.append(V_ACC)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the model with C = 0.000100\n",
            "Training Accuracy:  79.53333333333333 - Validation Accuracy:  90.6984126984127 \n",
            "\n",
            "Training the model with C = 0.001000\n",
            "Training Accuracy:  82.75555555555556 - Validation Accuracy:  91.98412698412697 \n",
            "\n",
            "Training the model with C = 0.010000\n",
            "Training Accuracy:  83.41777777777779 - Validation Accuracy:  91.6984126984127 \n",
            "\n",
            "Training the model with C = 0.100000\n",
            "Training Accuracy:  83.51777777777778 - Validation Accuracy:  91.5079365079365 \n",
            "\n",
            "Training the model with C = 1.000000\n",
            "Training Accuracy:  77.64444444444445 - Validation Accuracy:  87.06349206349206 \n",
            "\n",
            "Training the model with C = 10.000000\n",
            "Training Accuracy:  70.84222222222222 - Validation Accuracy:  80.12698412698413 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJykdil1CWnQ",
        "colab_type": "text"
      },
      "source": [
        "### Select the best model, embed the weights, and store the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YIOYW1HDRri",
        "colab_type": "code",
        "outputId": "841406c9-3191-41e8-bc6a-f88d357416eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# select the best model\n",
        "best_model_idx = np.array(svm_acc).argmax()\n",
        "best_model = svm_models[best_model_idx]\n",
        "print(\"Selected a model with accuracy: \", svm_acc[best_model_idx])\n",
        "\n",
        "# function to get svm model weights \n",
        "def get_weights(model,class_count):\n",
        "  perm_labels = np.array([model.label[index] for index in range(class_count)])\n",
        "  perm_labels = np.argsort(perm_labels)\n",
        "  return np.array([model.get_decfun(label_idx=label_index)[0] for label_index in perm_labels])\n",
        "\n",
        "# get svm model weights\n",
        "weights=get_weights(best_model,class_count)\n",
        "# embed the weights\n",
        "model.layers[svm_layer].set_weights([weights.transpose()])\n",
        "# save the model\n",
        "model.save(model_name)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected a model with accuracy:  91.98412698412697\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
